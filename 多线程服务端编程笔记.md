<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->


- [多线程服务端编程笔记](#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0)
  - [第一部分 C++多线程系统编程](#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-c%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B)
    - [1. 线程安全的对象生命期管理](#1-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%AF%B9%E8%B1%A1%E7%94%9F%E5%91%BD%E6%9C%9F%E7%AE%A1%E7%90%86)
    - [2. 线程同步精要](#2-%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%B2%BE%E8%A6%81)
    - [3. 多线程服务器的适用场合与常用编程模型](#3-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E9%80%82%E7%94%A8%E5%9C%BA%E5%90%88%E4%B8%8E%E5%B8%B8%E7%94%A8%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B)
    - [4. C++ 多线程编程精要](#4-c-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E7%B2%BE%E8%A6%81)
    - [5. 高效的多线程日志](#5-%E9%AB%98%E6%95%88%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%97%A5%E5%BF%97)
  - [第二部分 使用 muduo 网络库](#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86-%E4%BD%BF%E7%94%A8-muduo-%E7%BD%91%E7%BB%9C%E5%BA%93)
    - [1. muduo 简介](#1-muduo-%E7%AE%80%E4%BB%8B)
    - [7. 一些编程示例](#7-%E4%B8%80%E4%BA%9B%E7%BC%96%E7%A8%8B%E7%A4%BA%E4%BE%8B)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 多线程服务端编程笔记

阅读 陈硕《Linux 多线程服务器编程 —— 使用 muduo C++ 网络库》笔记。

## 第一部分 C++多线程系统编程

### 1. 线程安全的对象生命期管理

1. C++观察者模式
    - 又叫 发布-订阅 模式，跟回调类似。      
    观察者模式：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。它还有两个别名，依赖(Dependents)，发布-订阅(Publish-Subsrcibe)。可以举个博客订阅的例子，当博主发表新文章的时候，即博主状态发生了改变，那些订阅的读者就会收到通知，然后进行相应的动作，比如去看文章，或者收藏起来。博主与读者之间存在种一对多的依赖关系。
    原文链接：https://blog.csdn.net/wuzhekai1985/article/details/6674984

---
2. __一个线程安全的类__ 应当满足一下三个条件：
    - 多个线程同时访问时，其表现出正确的行为。
    - 无论操作系统如何调度这些线程，无论这些线程的执行顺序如何交织。
    - 调用端代码无需额外的同步或其他协调动作。

3. __对象构造要做到线程安全，唯一的要求是在构造期间不要泄露 this 指针__，即：
    - 不要造构造函数中注册任何回调
    - 也不要在构造函数中把 this 传给跨线程的对象
    - 即便在构造函数的最后一行也不行

    因为在构造期间，这个对象是一个半成品对象，如果 this 被泄露给其他对象，会造成难以预料的后果。

4. __对象析构的线程安全__
    - 因为析构函数会将 mutex 也销毁，所以使用 mutex 对析构函数进行加锁，也会产生无法预料的行为。所以， delete 对象之后把指针设置为 NULL 这样的单线程中的常规操作，在多线程中是不对的。所以，当 mutex 为类的数据成员时，mutex 只能用于同步本 class 其他数据成员的读写，而不能够保护安全地析构。

    - 对于一个函数要锁住相同类型的多个对象时，为了防止死锁，可以比较 mutex 对象的地址，始终先加锁地址较小的 mutex

5. 对于线程安全的 Observer 模式的实现
    - 使用一个 Observer 类作为订阅者，一个 Observable 类作为发布者，每个订阅者只能订阅一个发布者的消息，而每个发布者维护一个订阅者的向量，并且向所有订阅者发送通知。但问题在于，发布者想要向其所有订阅者发布消息时，需要知道其订阅者是否还活着，这个问题是很困难的。因为发布者存储其所有订阅者的指针，单通过这个指针是无法判断订阅者是否存活。

    - 一个好的解决办法是使用智能指针。shared_ptr/weak_ptr 的“计数“是原子操作，具有很高的效率。应用到 Observer 模式上时，只要让 Observable 对象保存 weak_ptr<Observer> 即可，这样就能很容易地知道这个发布者（Observable）的某个订阅者（Observer）是否存活。

    - [非线程安全的 Observer 代码](https://github.com/chenshuo/recipes/blob/master/thread/test/Observer.cc)
    - [线程安全的 Observer 代码](https://github.com/chenshuo/recipes/blob/master/thread/test/Observer_safe.cc)

---
6. shared_ptr 技术与陷阱
    - 意外延长对象的生命期
        - 例如不小心遗留了一份拷贝，则对象永远不会被释放。
    - 函数参数
        - 为了避免拷贝 shared_ptr 产生的开销，可以在最外层持有一个 shared_ptr 实体，然后以 pass by const reference 的方式将该 shared_ptr 传递给别的函数。
    - 析构动作在创建时被捕获
        - 虚析构不再是必须的
        - `shared_ptr<void>` 可以持有任何对象，而且能安全地释放
        - 二进制兼容性。即使指针所指的对象大小变了，旧的客户代码仍然可以使用新的动态库，无需重新编译。
        - 析构动作可以定制

    - 现成的 RAII handle
        - RAII: 每一个明确的资源配置动作（例如 new）都应该在单一语句中执行，并在该语句中立刻将配置获得的资源交给 handle 对象，程序中一般就无需再出现 delete. 通常做法是 owner 持有指向 child 的 shared_ptr，child 持有指向 owner 的 weak_ptr. 
        - 例如发布订阅模式中，发布者（被订阅者）需要存储订阅者的 weak_ptr，而订阅者需要存储发布者的 shared_ptr，这样就能保证只要还有订阅者存在，发布者就不会被释放。

---
7. 对象池
    - 理想情况下，为了节省系统资源，可以使用一个对象池，这个对象池根据 key 返回对应的对象，如果对象不存在则创建一个新的对象，每个对象只有一份拷贝，当这个对象没有在任何地方被使用时就应该被析构以释放内存。

    - 但是存在一些问题，例如对象无法自动释放（使用 shared_ptr），以及可能会造成内存泄漏（使用 weak_ptr），或者潜在的竞争条件等（例如尝试调用已经被析构的对象，例如当对象引用计数为0时，使用该对象的 shared_ptr 的定制析构功能，使用 Factory 的 this 指针去删除map中的项。但是如果 Factory 对象池对象先被析构，其产生的对象后被析构，则这时 this 指针已经不存在了）。

    - C++11 `<memory>` 提供 `std::enable_shared_from_this`，继承自这个类的类的 shared_from_this() 指针是 shared_ptr，这样可以保证在对象池所产生的对象被全部销毁前，对象池一定还活着，这样就能够正常删除map中的项，而不会造成线程安全问题。

    - 像上边那样做，固然是解决了线程安全的问题，但有时需要”如果对象还活着，就调用它的成员函数，否则忽略“的语义，就像 Observable::notifyObservers() 那样，作者称之为”弱回调“。这时可以使用 weak_ptr，将其 bind 到 shared_ptr 的回调函数里，这样对象池的生命周期就不会被延长。在回调时先尝试将 weak_ptr 升级为 shared_ptr，如果失败就什么都不用做了。

8. "用流水线，生产者消费者，任务队列这些有规律的机制，最低限度地共享数据。这时我所只最好的多线程编程的建议了。"
---

### 2. 线程同步精要

1. 线程同步的四项原则：
    - 首要原则是尽量最低限度地共享对象，减少需要同步的场合。如果非要共享对象，优先考虑 immutable 对象；实在不行才暴露可修改的对象，并用同步措施来充分保护它。
    
    - 其次是使用高级的并发编程构件，如 TaskQueue、Producer-Consumer Queue、CountDownLatch 等等。

    - 最后不得已必须使用底层同步原语时，只用非递归的互斥器(mutex)和条件变量，慎用读写锁，不要用信号量。

    - 除了使用 atomic 整数之外，不自己编写 lock-free 代码，也不要用内核级同步原语。s


2. 对于上面第三条，作者提供了几个使用互斥器 mutex 的原则：
    - 用 RAII 手法封装 mutex 的创建、销毁、加锁和解锁这四个操作。
    - 只用非递归的 mutex （即不可重入的 mutex）
    - 不手工调用 lock() 和 unlock() 函数，一切交给栈上的 Guard 对象的构造和析构函数负责(在 C++11 中提供了 `<mutex> std::lock_guard<>` 类模板用来对互斥量加锁。 但也提供了 `std::unique_lock<>` 类模板，比前者更为灵活。作者在书中都使用的是 boost 库，未使用 C++11 STL)。这种做法成为 __Scoped Locking__.

    - 在每次构造 Guard 对象的时候，思考一路上（调用栈上）已经持有的锁，防止因加锁顺序不同而导致死锁。（其实最好的办法是，尽量不要同时对多个互斥量加锁，从根本上避免死锁）

    作者也提出了一些次要原则：  
    - 不使用跨进程的 mutex，进程间通信只用 TCP sockets.
    - 加锁、解锁在同一个线程，线程 a 不能去 unlock 线程 b 已经锁住的 mutex（RAII 自动保证)。
    - 别忘了解锁（RAII自动保证）
    - 不重复解锁（RAII自动保证）
    - 必要的时候可以考虑用 PTHREAD_MUTEX_ERRORCHECK 来排错
---
3. 条件变量用于等待某个条件成立。学名叫做 __管程（monitor）__。 使用条件变量的正确方式：
    1. 必须与 mutex 一起使用，该布尔表达式的读写需受此 mutex 保护。
    2. 在 mutex 已上锁的时候才能调用 wait().
    3. 把判断布尔条件和 wait() 放到 while 循环中。目的是防止伪唤醒，这一点十分重要***********

        书中提供的线程安全地队列的 dequeue() 函数：
        ```cpp
        std::mutex mtx;
        std::condition_variable cv;
        std::deque<int> q;

        int dequeue(){
            std::unique_lock<std::mutex> lk(mtx);
            while(q.empty()){       // 这里必须用 while ，而不是 if !!!!!!
                cv.wait(lk);      // 这里会原子地解锁 mutex 并进入等待，不会死锁。
            }
            assert(!q.empty());
            int top = q.front();
            q.pop_front();
            return top;
        }
        ```
    
        其实也可以使用《C++并发编程实战》中的做法，使用 lambda 表达式：  

        ```cpp
        std::shared_ptr<T> wait_and_pop(){
        std::unique_lock<std::mutex> lk(mtx);
        cond.wait(lk,                       // 这样也能完美避免伪唤醒
            [this]{ return !q.empty(); }
        );

        std::shared_ptr<T> sptr(std::make_shared<T>(q.front()));
        q.pop();
        return sptr;
        }
        ```

    至于伪唤醒，是因为如果使用 if，一旦 wait() 条件达成，线程收到通知被唤醒时，与此同时可能有其他的线程也被唤醒，而这时还是会导致锁的争用，一些得不到锁的线程需要继续等待，所以这里必须要用 while 而不是 if.
---
4. __倒计时 CountDownLatch__，一种高级同步措施，由条件变量来实现（条件变量作为一种低级同步原语，很少直接使用，CountDownLatch 是条件变量一个非常经典的应用）。倒计时主要有两种用途：
    - 主线程发起多个子线程，等这些子线程各自都完成一定的任务后，主线程才继续执行。__通常用于主线程等待多个子线程完成初始化__
    - 主线程发起多个子线程，子线程都等待主线程，主线程完成一些其他任务之后通知所有子线程开始执行。__通常用于多个子线程等待主线程发出”起跑“命令__

        ```cpp
        // CountDownLatch 接口
        class CountDownLatch : boost::noncopyable{
        public:
            explicit CountDownLatch(int _count);     // 倒数几次
            void wait();
            void countDown();

        private:
            mutable MutexLock mutex;
            Condition cv;
            int count;
        }
        ```

        ```cpp
        // CountDownLatch 实现
        CountDownLatch::CountDownLatch(int _count)
            : mutex(), cv(mutex), count(_count) {}

        void CountDownLatch::wait(){
            MutexLockGuard lock(mutex);
            while(count > 0)
                condition.wait();
        }

        void CountDownLatch::countDown(){
            MutexLockGuard lock(mutex);
            --count;
            if(count == 0)
                cv.notifyAll();
        }
        ```

---
5. __不要用读写锁和信号量__

    - 对于读写锁，简而言之，非但不会明显的提升性能，还会导致很多错误。所以不要用读写锁替换 mutex
    - 对于信号量，条件变量配合互斥器可以完美替代信号量的功能，而且不容易用错。  
    但是条件变量和互斥器都说很底层的同步原语，最好不要直接使用，而是使用它们来实现高级的并发编程工具。（一个多线程程序如果大量使用 mutex 和 condition variable 来同步，基本跟用铅笔刀锯大树没什么区别）


6. 封装 MutexLock、MutexLockGuard、Condition，代码详见作者的 Github。 [代码地址](https://github.com/chenshuo/muduo/tree/master/muduo/base)，分别在 `Mutex.h` 和 `Condition.h, Condition.cc` 中。作者是使用 <pthread.h> 实现的。实际上我觉得完全可以使用 C++11 提供的多线程库来代替。

7. 线程安全的 Singleton 实现。使用 pthread_once_t 来保证懒加载的线程安全。

8. 不要使用 sleep() / usleep() / nanosleep()。除非是在写测试，或想有意延长临界区从而复现死锁时。 生产代码中的线程的等待可分为两种：
    - 等待资源可用（例如等待在条件变量上）
    - 等着进入临界区（等在 mutex 上）

    如果等待某个时间发生，那么应该采用条件变量或IO事件回调，不能用 sleep 来轮询，这是非常业余的做法。在用户态做轮询（polling）是低效的。

---
9. 使用 shared_ptr 实现 copy-on-write ，读写锁的功能。  
    - 例子：解决观察者模式中发布者 Observable 的 post() 和 traverse() 死锁。
        ```cpp
        MutexLock mutex;
        boost::shared_ptr<vector<Foo>> g_foos;

        void traverse(){
            auto foos;
            // 临界区，引用计数++
            {
                MutexLockGuard lock(mutex);
                foos = g_foos;
                assert(!g_foos.unique());       // 这时 g_foos 一定不能是unique
            }

            for(auto it = foos->begin(); it != foos->end(); ++it)
                it->doit();
        }   // 引用计数--， 临时的 shared_ptr foos 被析构

        void post(const Foo& f){
            printf("post\n");
            // 进入临界区
            MutexLockGuard lock(mutex);     // 如果有其他线程在写，会阻塞在这里
            if(!g_foos.unique()){           // 如果有其他线程在读，则拷贝一份再写
                g_foos.reset(new FooList(*g_foos));
                printf("copy the whole list\n");
            }
            assert(g_foos.unique());        // 这时 g_foos 已被重置，一定要是 unique
            g_foos->push_back(f);
        }
        ```

    - 用 mutex 替代读写锁的核心思想在于，当读的时候直接尝试加锁读取数据的引用，这样支持多个并发线程同步读；当写的时候如果其他线程正在读（shared_ptr 引用计数不为1），则创建一个副本，在副本上写，写完后替换，如果没有其他线程在读（shared_ptr 引用计数为1 ，只有自己在引用）则直接写。写的时候要全程加锁，防止写操作不同步。

    - Copy-on-write: 写入时复制。假定多方需要使用同一个资源时，没有必要为每一方都创建该资源的一个完整的副本，反而令多方共享这个资源（获取引用），当某方需要修改资源的某处时，利用引用计数，把该处复制一个副本，再把跟新的内容写入该副本中，从而节省创建多个完整副本时带来的空间和时间上的开销。

---
### 3. 多线程服务器的适用场合与常用编程模型

1. __单线程服务器的常用编程模型__
    - Reactor 模式。即 "non-blocking IO + IO multiplexing" (非阻塞IO 和 IO多路复用模型)。 程序的基本结构是一个事件循环（event loop），以事件驱动（event-driven）和事件回调的方式实现业务逻辑。Reactor 模式对 IO 密集型应用是个不错的选择。 缺点在于要求事件回调函数必须是非阻塞的。 对于网络IO的请求响应式协议，容易割裂业务逻辑，不易维护。
        ```cpp
        while(!done){
            int timeout_ms = max(1000, getNextTimedCallback());
            int retval = ::pool(fds, nfds, timeout_ms);
            if(retval < 0){
                // 处理错误，回调用户的 error handler
            }else{
                // 处理到期的 timers，回调用户的 timer handler
                if(retval > 0){
                    // 处理 IO 事件，回调用户的 IO event handler
                }
            }
        }
        ```

    - Proactor 模式。知乎上的解释：首先它们都是IO复用下的事件驱动模型，然后就从同步异步这两个点来切入概念。注意关键区别在于何时IO，reactor是关心就绪事件，比如可读了，就通知你，就像epoll_wait 。proactor关心的是完成比如读完了，就通知你。  
    [Reactor和Proactor的解释](https://www.zhihu.com/question/26943938)  
    [IO多路复用的解释](https://www.zhihu.com/question/28594409)

---
2. __多线程服务器的常用编程模型__
    1. 每个请求创建一个线程，使用阻塞式IO操作。
    2. 使用线程池，同样使用阻塞式IO操作。 比第一种性能高。
    3. __使用 non-blocking IO + IO multiplexing，one loop per thread__

    4. Leader/Follower 等高级模式。

    - __One loop per thread__
        - 在此模式下，程序里的每个 IO 线程有一个 event loop（或者叫 Reactor），用于处理读写和定时事件，代码框架与上边的 Reactor 例子相同。
        - 这种模式的好处在于：
            - 线程数目基本固定，不会频繁创建和销毁线程
            - 可以很方便地在线程间调配负载
            - IO事件发生的线程是固定的，同一个TCP链接不必考虑事件并发

    - __线程池__
        - 对于没有IO只有计算任务的线程，使用 event loop 会导致资源浪费，这里作者使用阻塞队列来实现：
            ```cpp
            typedef boost::function<void()> Functor;    // 函数对象，即任务
            BlockingQueue<Functor> taskQueue;       // 线程安全地阻塞队列

            // 工作线程
            void workerThread(){
                while(running){
                    Functor task = taskQueue.take();
                    task();
                }
            }

            // 启动容量为 N 的线程池
            int N = num_of_computing_threads;
            for(int i = 0; i < N; ++i){
                create_thread(&workerThread);       // 启动线程
            }

            Foo foo;
            Functor task = boost::bind(&Foo::calc, &foo);
            taskQueue.post(task);
            ```
            实际使用时封装成类即可。  除了任务队列还可以实现数据的生产着消费者队列，这时队列中是数据类型而不是函数对象。

        - 作者推荐的C++多线程服务器端编程模式为：one loop per thread + thread pool. 其中 event loop（IO loop）用作 IO multiplexing，配合 non-blocking IO 和定时器。thread pool 用来做计算，具体可以是任务队列或数据生产者消费者队列。

---
3. __进程间通信 IPC 只用TCP__
    - 进程间通信方法如 管道、消息队列、共享内存、信号、Sockets等等。

    - 作者这里首选 Sockets(主要指TCP)，好处在于可以跨主机、具有伸缩性，由单个主机扩展到多台机器，只需做少量更改（如host:port）配置就能继续用，而其他很多IPC方法都不能跨机器。

    - TCP port由一个进程独占，比较容易从错误中恢复，可以避免程序重复启动。两个进程使用TCP进行ICP，一个进程崩溃另一个能快速感知到（连接被操作系统关闭）。TCP还有一个好处就是可以跨语言，服务器端和客户端可以使用不同的语言。

    - __分布式系统使用TCP长连接通信__。宏观上看，一个分布式系统是由运行在多台机器上的多个进程组成的，进程之间采用 TCP 长连接通信。作者说：提倡使用多线程，并不是把整个系统放到一个进程里实现，而是功能划分后，在实现每一类进程服务时，在必要时可使用多线程来提高性能。  
        - 使用TCP长连接容易定位分布式系统中服务之间的依赖关系。
        - 通过接收和发送队列的长度也较容易定位网络或程序故障。

---
4. __多线程服务器的适用场合__
    - "服务器开发"用一句话说：跑在多核机器上的Linux用户态的没有GUI的长期运行的网络应用程序，通常是分布式系统的组成部件。

    - 开发服务器端程序的一个基本任务是 __处理并发连接__，主要有两种方式：
        - __当”线程“很廉价时__，这时一个线程只处理一个TCP连接，通常使用阻塞IO。这里的”线程“由语言的 runtime 自行调度，与操作系统线程不是一回事。（例如Python gevent, Go goroutine，Erlang actor）

        - __当线程很宝贵时__，一台机器只能创建于 CPU 数目相等的线程。这时一个线程要处理很多个 TCP 连接上的 IO，通常使用 non-blocking IO + IO multiplexing。（muduo就是如此。再例如libevent、Netty）。这里的线程是原生线程，能够被操作系统的任务调度器看见。

    - 只考虑一台机器时，如果要在一台机器上提供一种服务或执行一个任务，可用的模式有：
        - 模式1. 运行一个单线程的进程： 不可伸缩，不能发挥多核能力。
        - 模式2. 运行一个多线程的进程： 多线程程序很难写，而且不比模式3有优势。但有时还是要使用多线程。
        - __模式3. 运行多个单线程的进程： 公认的主流模式。__
            - 3a：简单地把模式1中的进程运行多份。
            - 3b：主进程 + worker进程

        - 模式4. 运行多个多线程的进程： 最蠢的方法。

    - 当程序可能会 fork() 创建新进程，或程序 CPU 占用率被限制时，必须使用单线程。

    - 单线程程序的优点：简单。例如使用 Reactor 模式， 但缺点在于它是非抢占的，只能按顺序执行，有可能优先级高的事件需要等待优先级低的事件。 而相比起来，多线程程序无论是 IO bound 还是 CPU bound的服务，都没有什么性能上的优势。就算是 CPU bound，采用上边的模式 3a. 既简单又能发挥多核优势。

    - 但多线程程序依然有用：能够提高响应速度，让IO和”计算“相互重叠，降低 latency。虽然多线程不能提高绝对性能，但能够提高平均响应性能。作者提出了一些能使用多线程程序的场景或条件，例如：有多个CPU可用，程序能Scale Up，线程间需要共享数据且共享数据可以修改（否则使用模式3即可），提供有优先级的服务，程序要有相当的计算量（不是简单地IO bound 或 CPU bound程序），利用异步操作，通过多线程能够有效地划分责任与功能（例如单线程的 Reactor 模式的 event loop 逻辑上就可能比较混乱）。

    - 多线程程序中线程的分类
        - IO线程：主循环是 IO multiplexing，阻塞地等在 select/poll/epoll_wait 系统调用上。
        - 计算线程：主循环是blocking queue,阻塞地等在 condition variable 上。一般位于线程池中，一般不涉及IO，要避免阻塞操作。
        - 第三方库线程：例如logging 或 数据库连接线程。

---
5. 最后，作者在这里提供了一些 Q&A，感觉非常有帮助，有可能会在面试中出现。

    - Linux 能同时启动多少个线程？  
        > 一个进程大约能启动 300 个线程（按线程栈默认大小10MB计算）。64bit 系统能大大增加，但实际上在线程为稀有资源时，无需建立太多线程。
    
    - 多线程能提高并发度吗？
        > 如果指的是“并发连接数”，则不能。这里指的是如果使用 thread per connection，对每个连接都用单独线程来处理，则不能提高并发连接数。但如果使用 event loop，异步 IO + IO复用（+线程池）的方法，则单个 event loop 可以处理 1万个 并发长连接。对于 multi-loop 可以处理更多。  
        > 作者：IO复用不是复用的IO连接，而是复用线程。

    - 多线程能提高吞吐量吗？
        > 对于计算密集型服务，不能。因为 CPU 都是满载的。但为了在并发请求数很高时也能保持稳定吞吐量，可以用线程池，线程池大小遵循 __“阻抗匹配原则”__。

    - 多线程能降低响应时间吗？
        > 如果设计合理，充分利用多核资源，可以降低平均响应时间。这里举了两个例子，当用多线程处理输入时，可以按 round-robin 把新连接分派给其中一个输入线程，这样读取用户的输入就可以多核并行，从而提高速度。第二个例子是用多线程分担负载，例如使用 BlockingQueue + 线程池，谁做完了当前任务就再去领取下一个，平均响应时间比单线程快很多。

    - 多线程程序如何让 IO 和 计算 相互重叠，降低 latency？
        > 把 IO 操作通过 BlockingQueue 交给别的线程去做，自己不必等待。这样自身线程可以继续等待或处理其他连接。
    
    - 为什么第三方库往往要用自己的线程？
        > 在 Reactor 模式下，第三方库有可能会阻塞主线程，从而主线程无法处理新连接。

    - 线程池大小的 __阻抗匹配原则__？
        > 密集计算所占任务的比重为 P，系统一共有 C 个 CPU，则线程池大小通常为 T = C/P，是较为合适的。但是当 P < 0.2 时就不再适用。例如 C = 8，P = 0.5，这样 T = 16，这样就有16个大概 50% 繁忙的线程，从而能占满 CPU。

    - 多线程的进程，和多个相同的单线程的进程，如何选择？
        > 可以根据工作集（响应一次请求所访问的内存大小）大小来取舍。工作集较大用多线程，这样避免 CPU Cache 总是换进换出。否则就用单线程多进程，因为编程更便利。
        

---
### 4. C++ 多线程编程精要

1. 基本线程原语的选用：thread，mutex，condition，就可以完成任何多线程编程任务。但一般不会直接使用，而是封装成更高级的线程同步原语。例如：ThreadPool，CountDownLatch等。 作者不推荐使用读写锁，因为实际情况下并不能提高性能，而且如果要求优化读操作的延迟，用读写锁并不合适（写操作会阻塞读操作）。

2. 线程的创建于销毁守则：
    - 程序库不应该在未提前告知的情况下创建自己的“背景线程”。
    - 尽量用相同的方式创建线程，例如：muduo::Thread.
    - 在进入 main() 函数之前不应该启动线程。
    - 程序中线程的创建最好能在初始化阶段全部完成。

3. 多线程与 IO
    - 本书只讨论同步IO，包括阻塞与非阻塞，不讨论异步IO。
    - 对于网络IO，多个线程操作同一个socket文件描述符会很麻烦，但这往往是在程序逻辑设计有问题时才会出现。同时，如果两个线程同时读或写同一个 TCP socket，都会很麻烦。所以，不如就 __始终让同一个线程操作一个 socket__。

    - 对于多线程磁盘IO，每个磁盘匹配一个线程，把所有针对此磁盘的IO都挪到同一个线程。能够100%正确的方法是，__一个文件只由一个进程中的一个线程来读写__

4. __用RAII包装文件描述符__。RAII就是C++编程的核心之一。

5. 多线程不要使用 fork() 来创建子进程。

6. 多线程下不要使用 Linux/Unix 的信号 Signal 机制。

---

### 5. 高效的多线程日志

1. 这一章主要介绍了 muduo 库日志部分的实现。这里的日志指的是诊断日志，即文本的、供人阅读的日志，通常用于故障诊断和追踪。在服务端编程中，日志是必不可少的。对于关键进程，日志通常要记录：
    - 收到的每条内部消息的 id
    - 收到的每条外部消息全文
    - 发出的每条消息的全文，每条消息都有唯一的全局 id
    - 关键的内部状态变更，等等  

    __每条日志都要有时间戳__

2. 一个日志库可分为 __前端__ 和 __后端__ 两部分。前端是供客户程序使用的接口，并生成日志消息；后端负责把日志消息写到目的地（如文件或db）。这两部分的接口可能只有一个：  
    ```void output(const char* message, int len)'```

    - 每个线程有自己的前端，整个程序公用一个后端。是一个典型的 __多生产者-消费者__ 问题。

    - 对于分布式系统中的服务进程，目的地只能是本地文件。因为往网络写日志是不可靠的，而且还会徒增带宽消耗。

    - 为了避免程序崩溃导致最后若干条日志丢失（因为日志库不能一直将消息 flush 到磁盘，也不能对每条消息都 open/close 文件，性能开销太大）。这里使用两个办法：
        - 定期（默认3s）将缓冲区的日志消息 flush 到磁盘；
        - 每条内存中的日志消息都带有 cookie，其值为某个函数的地址，这样通过在 core dump 文件查找 cookie 就能找到尚未来得及写入磁盘的消息。

3. 对于性能部分，一般要求能应对大量产生日志的场景（如1GB/min），以及每秒写成千上万条且不影响性能，而且不能阻塞正常执行的流程，多线程程序中不造成争用等。muduo 能在一般的 PC 上一秒写 200w 条消息。这里提出了几点优化的点：
    - 时间戳字符串的日期和具体时间按两部分缓存，一秒内的多条日志只需要格式化微秒部分，其他部分已经缓存好，不用每次都做系统调用查看当前时间。
    - 日志消息前4个字段是定长的。
    - 线程 id 预先格式化为字符串，在输出日志消息时只需简单拷贝几个字节。
    - 每行日志消息源文件部分采用编译期计算获得 basename，就没有了运行期开销。

4. 对于多线程的场景，需要能够实现异步日志，并且保证线程安全，多个线程写入的消息不会交织。解决办法为：用一个背景线程负责收集日志消息，并写入日志文件，其他业务线程只管往这个“日志线程”发送日志消息即可，这称为“异步日志或非阻塞日志”。这里采用的是所谓“双缓冲”技术，准备两块 buffer: A，B。当 buffer A 写满后，交换 A 和 B，让后端将 A 的数据写入文件，这时前端开始往 B 中填入消息，如此往复。这样实际上前端不是一条一条将消息发送给后端，而是攒到一起发给后端，相当于批处理，这样能够减少线程唤醒品读，降低开销。同时，就算未满，也会3秒交换一次。 在实际实现中这里使用了四个缓冲区，从而进一步减小或避免日志前端的等待。具体实现略。  

---
## 第二部分 使用 muduo 网络库

### 1. muduo 简介

1. 要上手使用的话，只需要掌握五个关键类：Buffer、EventLoop、TcpConnection、TcpClient、TcpServer。

2. 线程模型
    - one loop per thread + thread pool 模型。

    - TcpServer 支持多线程，具有两种模式：
        - 单线程。accept() 与 TcpConnection 用同一个线程做 IO
        - 多线程。accept() 与 EventLoop 在同一个线程，另外创建一个 EventLoopThreadPool，新到的连接会以 round-robin 的方式分配到线程池。
    
3. __TCP网络编程的本质就是处理三个半事件__

    - __连接的建立__。
    - __连接的断开__。
    - __消息到达，文件描述符可读__。（这个最为重要，决定了网络编程风格，如阻塞或非阻塞，对分包的处理，应用层缓冲设计等等。）
    - __消息发送完毕__。（半个事件）。发送完毕是指将数据写入操作系统缓冲区，交给TCP负责数据发送和重传，不代表对方已收到。

4. 性能评测，主要考察了一下几个方面：
    - 吞吐量
    - 事件处理效率（处理一批事件需要多少时间）
    - 延迟

5. 介绍了12种常见的并发网络服务程序设计方案。其中着重说几点
    - 前4种都是阻塞式，没什么好说的。

    - 方案5：基本的单线程 Reactor 方案。由网络库搞定数据收发，客户代码只需要关心业务逻辑。但是适合IO密集型应用，但不适合计算密集型（因为在当前线程做计算会阻塞 Event Loop）。

    - 方案6：收到请求，不在 Reactor 线程计算，而是创建一个新线程计算。非常初级，为每个请求创建线程，开销较大，而且无法保证同一个连接中几个请求的回复顺序（顺序性）。

    - 方案7：为每个连接创建一个线程，每个连接的请求都交给固定的线程来算。虽然保证了顺序性，但更蠢了，CPU利用率不如方案6高。

    - 方案8：一个Reactor线程处理IO，计算任务交给线程池做。但无法保证顺序性。

    - __方案9：muduo 内置的多线程方案：一个 main Reactor 负责 accept() 连接，把连接挂在某个 subReactor 中（采用 Round-robin 方式选取），该连接的所有操作都在这个 subReactor 所处线程完成。能够保证顺序性（一个连接一直由一个 subReactor 处理）。 对于计算不太密集的情况，小规模计算在IO线程做就可以了，实用性很强。__

    - 方案11：把8和9混合，既使用多个 Reactor 处理IO，又使用线程出处理计算。

---
### 7. 一些编程示例

1. 五个简单的 TCP 示例。

    - discard
        - 功能：收到消息并丢弃，然后断开连接。
        - 只需要关注三个半事件中的，"消息/数据到达"事件。

    - daytime
        - 功能：短连接，发送完当前日期和时间，主动断开连接。
        - 只需关注三个半事件中的，“连接已建立”事件。

    - time
        - 功能：跟daytime几乎一样，只是返回一个二进制时间，这里主要关注客户端。
        - 客户端需要关注，"消息/数据到达"事件。

    - echo
        - 功能：短连接，把客户发来的消息原封不动发回去。
        - 双向协议。但还是只需要关注三个半事件中的，“消息/数据到达事件”。

    - chargen
        - 功能：不断地向用户发送数据。
        - 只发送不接收，只关注那半个，“消息/数据发送完毕”事件。


2. 文件传输
    - 使用 send() 函数发送数据。但达到了内存消耗与文件大小无关，只与并发连接数有关。一共三个版本。

    - 版本一：把全部文件读入 string，一次性调用 send() 发送。这样不用担心文件发送不完整，也不用担心 send() 之后立刻 shutdown() 会有问题。这个版本的内存消耗与文件大小成正比。

    - 版本二：采用流水线思路，当新建连接时，先发送前64Kb数据，发送完毕后通过 onWriteComplete() 回调函数发送下 64Kb 数据，直到整个文件发送完毕。这样内存消耗与文件大小无关。

    - 版本三：用 shared_ptr 的自定义删除器功能，使FILE* 文件指针的生命周期和 TcpConnection 一样长。其实就是用 shared_ptr 做 RAII，将他俩生命周期绑定，连接断开时会自动释放FILE*，不会造成资源泄露，同时保证了异常安全性。


---
3. Boost.Asio 的聊天服务器实现。

    - TCP是字节流协议，这一点跟UDP不同。对于TCP短连接，无需处理分包问题。但对于长连接，接收端有时会同时收到两条信息，也会只收到半条信息，这就需要应用层来处理分包了。这里的处理方法是：__在每条消息头部加一个长度字段__。

    - 聊天服务的特点在于：连接之间的数据有交流，服务端从a连接收到的数据要发给b连接。

    - 首先，使用单独的 codec 类处理打包和分包。相当于一个中间层，每次当Tcp Socket 可读时，从 Tcp Socket 获取到数据，当凑够一条完整消息时，将消息发给 Reactor 处理。也就是说，将数据到达和消息到达拆分开，当数据到达时由 codec 立刻去读数据，但消息到达的次数和消息数量是相同的。

    - 对于服务端，只需要维护一个当前连接的 set，当收到消息时，将消息转发给所有客户端即可。

    - 对于客户端，复杂性在于要同时读取用户从键盘的输入，还要使用 EventLoop 侦听消息，而 EventLoop 是线程独占的，读取用户输入不能阻塞 EventLoop。所以，这里使用 main() 函数正常读取键盘，由单独的 EventLoopThread 线程持有 EventLoop，每当读取到用户输入，就将数据转发给客户端 EventLoop。


---