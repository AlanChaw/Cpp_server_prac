<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->


- [多线程服务端编程笔记](#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0)
  - [第一部分 C++多线程系统编程](#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-c%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B)
    - [1. 线程安全的对象生命期管理](#1-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%AF%B9%E8%B1%A1%E7%94%9F%E5%91%BD%E6%9C%9F%E7%AE%A1%E7%90%86)
    - [2. 线程同步精要](#2-%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%B2%BE%E8%A6%81)
    - [3. 多线程服务器的适用场合与常用编程模型](#3-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E9%80%82%E7%94%A8%E5%9C%BA%E5%90%88%E4%B8%8E%E5%B8%B8%E7%94%A8%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 多线程服务端编程笔记

阅读 陈硕《Linux 多线程服务器编程 —— 使用 muduo C++ 网络库》笔记。

## 第一部分 C++多线程系统编程

### 1. 线程安全的对象生命期管理

1. C++观察者模式
    - 又叫 发布-订阅 模式，跟回调类似。      
    观察者模式：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。它还有两个别名，依赖(Dependents)，发布-订阅(Publish-Subsrcibe)。可以举个博客订阅的例子，当博主发表新文章的时候，即博主状态发生了改变，那些订阅的读者就会收到通知，然后进行相应的动作，比如去看文章，或者收藏起来。博主与读者之间存在种一对多的依赖关系。
    原文链接：https://blog.csdn.net/wuzhekai1985/article/details/6674984


2. __一个线程安全的类__ 应当满足一下三个条件：
    - 多个线程同时访问时，其表现出正确的行为。
    - 无论操作系统如何调度这些线程，无论这些线程的执行顺序如何交织。
    - 调用端代码无需额外的同步或其他协调动作。

3. __对象构造要做到线程安全，唯一的要求是在构造期间不要泄露 this 指针__，即：
    - 不要造构造函数中注册任何回调
    - 也不要在构造函数中把 this 传给跨线程的对象
    - 即便在构造函数的最后一行也不行

    因为在构造期间，这个对象是一个半成品对象，如果 this 被泄露给其他对象，会造成难以预料的后果。

4. __对象析构的线程安全__
    - 因为析构函数会将 mutex 也销毁，所以使用 mutex 对析构函数进行加锁，也会产生无法预料的行为。所以， delete 对象之后把指针设置为 NULL 这样的单线程中的常规操作，在多线程中是不对的。所以，当 mutex 为类的数据成员时，mutex 只能用于同步本 class 其他数据成员的读写，而不能够保护安全地析构。

    - 对于一个函数要锁住相同类型的多个对象时，为了防止死锁，可以比较 mutex 对象的地址，始终先加锁地址较小的 mutex

5. 对于线程安全的 Observer 模式的实现
    - 使用一个 Observer 类作为订阅者，一个 Observable 类作为发布者，每个订阅者只能订阅一个发布者的消息，而每个发布者维护一个订阅者的向量，并且向所有订阅者发送通知。但问题在于，发布者想要向其所有订阅者发布消息时，需要知道其订阅者是否还活着，这个问题是很困难的。因为发布者存储其所有订阅者的指针，单通过这个指针是无法判断订阅者是否存活。

    - 一个好的解决办法是使用智能指针。shared_ptr/weak_ptr 的“计数“是原子操作，具有很高的效率。应用到 Observer 模式上时，只要让 Observable 对象保存 weak_ptr<Observer> 即可，这样就能很容易地知道这个发布者（Observable）的某个订阅者（Observer）是否存活。

    - [非线程安全的 Observer 代码](https://github.com/chenshuo/recipes/blob/master/thread/test/Observer.cc)
    - [线程安全的 Observer 代码](https://github.com/chenshuo/recipes/blob/master/thread/test/Observer_safe.cc)


6. shared_ptr 技术与陷阱
    - 意外延长对象的生命期
        - 例如不小心遗留了一份拷贝，则对象永远不会被释放。
    - 函数参数
        - 为了避免拷贝 shared_ptr 产生的开销，可以在最外层持有一个 shared_ptr 实体，然后以 pass by const reference 的方式将该 shared_ptr 传递给别的函数。
    - 析构动作在创建时被捕获
        - 虚析构不再是必须的
        - `shared_ptr<void>` 可以持有任何对象，而且能安全地释放
        - 二进制兼容性。即使指针所指的对象大小变了，旧的客户代码仍然可以使用新的动态库，无需重新编译。
        - 析构动作可以定制

    - 现成的 RAII handle
        - RAII: 每一个明确的资源配置动作（例如 new）都应该在单一语句中执行，并在该语句中立刻将配置获得的资源交给 handle 对象，程序中一般就无需再出现 delete. 通常做法是 owner 持有指向 child 的 shared_ptr，child 持有指向 owner 的 weak_ptr. 
        - 例如发布订阅模式中，发布者（被订阅者）需要存储订阅者的 weak_ptr，而订阅者需要存储发布者的 shared_ptr，这样就能保证只要还有订阅者存在，发布者就不会被释放。

7. 对象池
    - 理想情况下，为了节省系统资源，可以使用一个对象池，这个对象池根据 key 返回对应的对象，如果对象不存在则创建一个新的对象，每个对象只有一份拷贝，当这个对象没有在任何地方被使用时就应该被析构以释放内存。

    - 但是存在一些问题，例如对象无法自动释放（使用 shared_ptr），以及可能会造成内存泄漏（使用 weak_ptr），或者潜在的竞争条件等（例如尝试调用已经被析构的对象，例如当对象引用计数为0时，使用该对象的 shared_ptr 的定制析构功能，使用 Factory 的 this 指针去删除map中的项。但是如果 Factory 对象池对象先被析构，其产生的对象后被析构，则这时 this 指针已经不存在了）。

    - C++11 `<memory>` 提供 `std::enable_shared_from_this`，继承自这个类的类的 shared_from_this() 指针是 shared_ptr，这样可以保证在对象池所产生的对象被全部销毁前，对象池一定还活着，这样就能够正常删除map中的项，而不会造成线程安全问题。

    - 像上边那样做，固然是解决了线程安全的问题，但有时需要”如果对象还活着，就调用它的成员函数，否则忽略“的语义，就像 Observable::notifyObservers() 那样，作者称之为”弱回调“。这时可以使用 weak_ptr，将其 bind 到 shared_ptr 的回调函数里，这样对象池的生命周期就不会被延长。在回调时先尝试将 weak_ptr 升级为 shared_ptr，如果失败就什么都不用做了。

8. "用流水线，生产者消费者，任务队列这些有规律的机制，最低限度地共享数据。这时我所只最好的多线程编程的建议了。"
---

### 2. 线程同步精要

1. 线程同步的四项原则：
    - 首要原则是尽量最低限度地共享对象，减少需要同步的场合。如果非要共享对象，优先考虑 immutable 对象；实在不行才暴露可修改的对象，并用同步措施来充分保护它。
    
    - 其次是使用高级的并发编程构件，如 TaskQueue、Producer-Consumer Queue、CountDownLatch 等等。

    - 最后不得已必须使用底层同步原语时，只用非递归的互斥器(mutex)和条件变量，慎用读写锁，不要用信号量。

    - 除了使用 atomic 整数之外，不自己编写 lock-free 代码，也不要用内核级同步原语。s

---
2. 对于上面第三条，作者提供了几个使用互斥器 mutex 的原则：
    - 用 RAII 手法封装 mutex 的创建、销毁、加锁和解锁这四个操作。
    - 只用非递归的 mutex （即不可重入的 mutex）
    - 不手工调用 lock() 和 unlock() 函数，一切交给栈上的 Guard 对象的构造和析构函数负责(在 C++11 中提供了 `<mutex> std::lock_guard<>` 类模板用来对互斥量加锁。 但也提供了 `std::unique_lock<>` 类模板，比前者更为灵活。作者在书中都使用的是 boost 库，未使用 C++11 STL)。这种做法成为 __Scoped Locking__.

    - 在每次构造 Guard 对象的时候，思考一路上（调用栈上）已经持有的锁，防止因加锁顺序不同而导致死锁。（其实最好的办法是，尽量不要同时对多个互斥量加锁，从根本上避免死锁）

    作者也提出了一些次要原则：  
    - 不使用跨进程的 mutex，进程间通信只用 TCP sockets.
    - 加锁、解锁在同一个线程，线程 a 不能去 unlock 线程 b 已经锁住的 mutex（RAII 自动保证)。
    - 别忘了解锁（RAII自动保证）
    - 不重复解锁（RAII自动保证）
    - 必要的时候可以考虑用 PTHREAD_MUTEX_ERRORCHECK 来排错
---
3. 条件变量用于等待某个条件成立。学名叫做 __管程（monitor）__。 使用条件变量的正确方式：
    1. 必须与 mutex 一起使用，该布尔表达式的读写需受此 mutex 保护。
    2. 在 mutex 已上锁的时候才能调用 wait().
    3. 把判断布尔条件和 wait() 放到 while 循环中。目的是防止伪唤醒，这一点十分重要***********

        书中提供的线程安全地队列的 dequeue() 函数：
        ```cpp
        std::mutex mtx;
        std::condition_variable cv;
        std::deque<int> q;

        int dequeue(){
            std::unique_lock<std::mutex> lk(mtx);
            while(q.empty()){       // 这里必须用 while ，而不是 if !!!!!!
                cv.wait(lk);      // 这里会原子地解锁 mutex 并进入等待，不会死锁。
            }
            assert(!q.empty());
            int top = q.front();
            q.pop_front();
            return top;
        }
        ```
    
        其实也可以使用《C++并发编程实战》中的做法，使用 lambda 表达式：  

        ```cpp
        std::shared_ptr<T> wait_and_pop(){
        std::unique_lock<std::mutex> lk(mtx);
        cond.wait(lk,                       // 这样也能完美避免伪唤醒
            [this]{ return !q.empty(); }
        );

        std::shared_ptr<T> sptr(std::make_shared<T>(q.front()));
        q.pop();
        return sptr;
        }
        ```

    至于伪唤醒，是因为如果使用 if，一旦 wait() 条件达成，线程收到通知被唤醒时，与此同时可能有其他的线程也被唤醒，而这时还是会导致锁的争用，一些得不到锁的线程需要继续等待，所以这里必须要用 while 而不是 if.
---
4. __倒计时 CountDownLatch__，一种高级同步措施，由条件变量来实现（条件变量作为一种低级同步原语，很少直接使用，CountDownLatch 是条件变量一个非常经典的应用）。倒计时主要有两种用途：
    - 主线程发起多个子线程，等这些子线程各自都完成一定的任务后，主线程才继续执行。__通常用于主线程等待多个子线程完成初始化__
    - 主线程发起多个子线程，子线程都等待主线程，主线程完成一些其他任务之后通知所有子线程开始执行。__通常用于多个子线程等待主线程发出”起跑“命令__

        ```cpp
        // CountDownLatch 接口
        class CountDownLatch : boost::noncopyable{
        public:
            explicit CountDownLatch(int _count);     // 倒数几次
            void wait();
            void countDown();

        private:
            mutable MutexLock mutex;
            Condition cv;
            int count;
        }
        ```

        ```cpp
        // CountDownLatch 实现
        CountDownLatch::CountDownLatch(int _count)
            : mutex(), cv(mutex), count(_count) {}

        void CountDownLatch::wait(){
            MutexLockGuard lock(mutex);
            while(count > 0)
                condition.wait();
        }

        void CountDownLatch::countDown(){
            MutexLockGuard lock(mutex);
            --count;
            if(count == 0)
                cv.notifyAll();
        }
        ```

---
5. __不要用读写锁和信号量__

    - 对于读写锁，简而言之，非但不会明显的提升性能，还会导致很多错误。所以不要用读写锁替换 mutex
    - 对于信号量，条件变量配合互斥器可以完美替代信号量的功能，而且不容易用错。  
    但是条件变量和互斥器都说很底层的同步原语，最好不要直接使用，而是使用它们来实现高级的并发编程工具。（一个多线程程序如果大量使用 mutex 和 condition variable 来同步，基本跟用铅笔刀锯大树没什么区别）


6. 封装 MutexLock、MutexLockGuard、Condition，代码详见作者的 Github。 [代码地址](https://github.com/chenshuo/muduo/tree/master/muduo/base)，分别在 `Mutex.h` 和 `Condition.h, Condition.cc` 中。作者是使用 <pthread.h> 实现的。实际上我觉得完全可以使用 C++11 提供的多线程库来代替。

7. 线程安全的 Singleton 实现。使用 pthread_once_t 来保证懒加载的线程安全。

8. 不要使用 sleep() / usleep() / nanosleep()。除非是在写测试，或想有意延长临界区从而复现死锁时。 生产代码中的线程的等待可分为两种：
    - 等待资源可用（例如等待在条件变量上）
    - 等着进入临界区（等在 mutex 上）

    如果等待某个时间发生，那么应该采用条件变量或IO事件回调，不能用 sleep 来轮询，这是非常业余的做法。在用户态做轮询（polling）是低效的。

9. 使用 shared_ptr 实现 copy-on-write ，读写锁的功能。  
    - 例子：解决观察者模式中发布者 Observable 的 post() 和 traverse() 死锁。
        ```cpp
        MutexLock mutex;
        boost::shared_ptr<vector<Foo>> g_foos;

        void traverse(){
            auto foos;
            // 临界区，引用计数++
            {
                MutexLockGuard lock(mutex);
                foos = g_foos;
                assert(!g_foos.unique());       // 这时 g_foos 一定不能是unique
            }

            for(auto it = foos->begin(); it != foos->end(); ++it)
                it->doit();
        }   // 引用计数--， 临时的 shared_ptr foos 被析构

        void post(const Foo& f){
            printf("post\n");
            // 进入临界区
            MutexLockGuard lock(mutex);     // 如果有其他线程在写，会阻塞在这里
            if(!g_foos.unique()){           // 如果有其他线程在读，则拷贝一份再写
                g_foos.reset(new FooList(*g_foos));
                printf("copy the whole list\n");
            }
            assert(g_foos.unique());        // 这时 g_foos 已被重置，一定要是 unique
            g_foos->push_back(f);
        }
        ```

    - 用 mutex 替代读写锁的核心思想在于，当读的时候直接尝试加锁读取数据的引用，这样支持多个并发线程同步读；当写的时候如果其他线程正在读（shared_ptr 引用计数不为1），则创建一个副本，在副本上写，写完后替换，如果没有其他线程在读（shared_ptr 引用计数为1 ，只有自己在引用）则直接写。写的时候要全程加锁，防止写操作不同步。

    - Copy-on-write: 写入时复制。假定多方需要使用同一个资源时，没有必要为每一方都创建该资源的一个完整的副本，反而令多方共享这个资源（获取引用），当某方需要修改资源的某处时，利用引用计数，把该处复制一个副本，再把跟新的内容写入该副本中，从而节省创建多个完整副本时带来的空间和时间上的开销。

---
### 3. 多线程服务器的适用场合与常用编程模型

1. __单线程服务器的常用编程模型__
    - Reactor 模式。即 "non-blocking IO + IO multiplexing" (非阻塞IO 和 IO多路复用模型)。 程序的基本结构是一个事件循环（event loop），以事件驱动（event-driven）和事件回调的方式实现业务逻辑。Reactor 模式对 IO 密集型应用是个不错的选择。 缺点在于要求事件回调函数必须是非阻塞的。 对于网络IO的请求响应式协议，容易割裂业务逻辑，不易维护。
        ```cpp
        while(!done){
            int timeout_ms = max(1000, getNextTimedCallback());
            int retval = ::pool(fds, nfds, timeout_ms);
            if(retval < 0){
                // 处理错误，回调用户的 error handler
            }else{
                // 处理到期的 timers，回调用户的 timer handler
                if(retval > 0){
                    // 处理 IO 事件，回调用户的 IO event handler
                }
            }
        }
        ```

    - Proactor 模式。知乎上的解释：首先它们都是IO复用下的事件驱动模型，然后就从同步异步这两个点来切入概念。注意关键区别在于何时IO，reactor是关心就绪事件，比如可读了，就通知你，就像epoll_wait 。proactor关心的是完成比如读完了，就通知你。  
    [Reactor和Proactor的解释](https://www.zhihu.com/question/26943938)  
    [IO多路复用的解释](https://www.zhihu.com/question/28594409)

2. __多线程服务器的常用编程模型__
    1. 每个请求创建一个线程，使用阻塞式IO操作。
    2. 使用线程池，同样使用阻塞式IO操作。 比第一种性能高。
    3. __使用 non-blocking IO + IO multiplexing，one loop per thread__

    4. Leader/Follower 等高级模式。

    - __One loop per thread__
        - 在此模式下，程序里的每个 IO 线程有一个 event loop（或者叫 Reactor），用于处理读写和定时事件，代码框架与上边的 Reactor 例子相同。
        - 这种模式的好处在于：
            - 线程数目基本固定，不会频繁创建和销毁线程
            - 可以很方便地在线程间调配负载
            - IO事件发生的线程是固定的，同一个TCP链接不必考虑事件并发

    - __线程池__
        - 对于没有IO只有计算任务的线程，使用 event loop 会导致资源浪费，这里作者使用阻塞队列来实现：
            ```cpp
            typedef boost::function<void()> Functor;    // 函数对象，即任务
            BlockingQueue<Functor> taskQueue;       // 线程安全地阻塞队列

            // 工作线程
            void workerThread(){
                while(running){
                    Functor task = taskQueue.take();
                    task();
                }
            }

            // 启动容量为 N 的线程池
            int N = num_of_computing_threads;
            for(int i = 0; i < N; ++i){
                create_thread(&workerThread);       // 启动线程
            }

            Foo foo;
            Functor task = boost::bind(&Foo::calc, &foo);
            taskQueue.post(task);
            ```
            实际使用时封装成类即可。  除了任务队列还可以实现数据的生产着消费者队列，这时队列中是数据类型而不是函数对象。

        - 作者推荐的C++多线程服务器端编程模式为：one loop per thread + thread pool. 其中 event loop（IO loop）用作 IO multiplexing，配合 non-blocking IO 和定时器。thread pool 用来做计算，具体可以是任务队列或数据生产者消费者队列。


3. __进程间通信 IPC 只用TCP__
    - 进程间通信方法如 管道、消息队列、共享内存、信号、Sockets等等。

    - 作者这里首选 Sockets(主要指TCP)，好处在于可以跨主机、具有伸缩性，由单个主机扩展到多台机器，只需做少量更改（如host:port）配置就能继续用，而其他很多IPC方法都不能跨机器。

    - TCP port由一个进程独占，比较容易从错误中恢复，可以避免程序重复启动。两个进程使用TCP进行ICP，一个进程崩溃另一个能快速感知到（连接被操作系统关闭）。TCP还有一个好处就是可以跨语言，服务器端和客户端可以使用不同的语言。

    - __分布式系统使用TCP长连接通信__。宏观上看，一个分布式系统是由运行在多台机器上的多个进程组成的，进程之间采用 TCP 长连接通信。作者说：提倡使用多线程，并不是把整个系统放到一个进程里实现，而是功能划分后，在实现每一类进程服务时，在必要时可使用多线程来提高性能。  
        - 使用TCP长连接容易定位分布式系统中服务之间的依赖关系。
        - 通过接收和发送队列的长度也较容易定位网络或程序故障。

4. __多线程服务器的适用场合__
    - "服务器开发"用一句话说：跑在多核机器上的Linux用户态的没有GUI的长期运行的网络应用程序，通常是分布式系统的组成部件。

    - 开发服务器端程序的一个基本任务是 __处理并发连接__，主要有两种方式：
        - __当”线程“很廉价时__，这时一个线程只处理一个TCP连接，通常使用阻塞IO。这里的”线程“由语言的 runtime 自行调度，与操作系统线程不是一回事。（例如Python gevent, Go goroutine，Erlang actor）

        - __当线程很宝贵时__，一台机器只能创建于 CPU 数目相等的线程。这时一个线程要处理很多个 TCP 连接上的 IO，通常使用 non-blocking IO + IO multiplexing。（muduo就是如此。再例如libevent、Netty）。这里的线程是原生线程，能够被操作系统的任务调度器看见。

    - 只考虑一台机器时，如果要在一台机器上提供一种服务或执行一个任务，可用的模式有：
        - 模式1. 运行一个单线程的进程： 不可伸缩，不能发挥多核能力。
        - 模式2. 运行一个多线程的进程： 多线程程序很难写，而且不比模式3有优势。但有时还是要使用多线程。
        - __模式3. 运行多个单线程的进程： 公认的主流模式。__
            - 3a：简单地把模式1中的进程运行多份。
            - 3b：主进程 + worker进程

        - 模式4. 运行多个多线程的进程： 最蠢的方法。

    - 当程序可能会 fork() 创建新进程，或程序 CPU 占用率被限制时，必须使用单线程。

    - 单线程程序的优点：简单。例如使用 Reactor 模式， 但缺点在于它是非抢占的，只能按顺序执行，有可能优先级高的事件需要等待优先级低的事件。 而相比起来，多线程程序无论是 IO bound 还是 CPU bound的服务，都没有什么性能上的优势。就算是 CPU bound，采用上边的模式 3a. 既简单又能发挥多核优势。

    - 但多线程程序依然有用：能够提高响应速度，让IO和”计算“相互重叠，降低 latency。虽然多线程不能提高绝对性能，但能够提高平均响应性能。作者提出了一些能使用多线程程序的场景或条件，例如：有多个CPU可用，程序能Scale Up，线程间需要共享数据且共享数据可以修改（否则使用模式3即可），提供有优先级的服务，程序要有相当的计算量（不是简单地IO bound 或 CPU bound程序），利用异步操作，通过多线程能够有效地划分责任与功能（例如单线程的 Reactor 模式的 event loop 逻辑上就可能比较混乱）。

    - 多线程程序中线程的分类
        - IO线程：主循环是 IO multiplexing，阻塞地等在 select/poll/epoll_wait 系统调用上。
        - 计算线程：主循环是blocking queue,阻塞地等在 condition variable 上。一般位于线程池中，一般不涉及IO，要避免阻塞操作。
        - 第三方库线程：例如logging 或 数据库连接线程。

---




